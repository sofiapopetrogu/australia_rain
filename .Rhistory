glm_model0 <- glm(data = rain_n_train0,
rain_n_train0$RainTomorrow ~ .,
family = binomial)
#R squared and Variance Inflation Factor (VIF)
#If the VIF value for a predictor variable is greater than 1, it indicates the presence of multicollinearity, suggesting that the predictor variable is highly correlated with other predictor variables in the model.
model_summary0 <- summary(glm_model0)
summary(glm_model0)
r2_0 <- 1 - (model_summary0$deviance/model_summary0$null.deviance) # 0.3698141
vif0 <- 1/(1-r2_0) # 1.586833
#Predict test with model
glm_predict0 <- predict(glm_model0, rain_n_test0, type = "response")
#Convert predictions into 0,1 based on different thresholds
threshold4 <- 0.4
threshold5 <- 0.5
threshold6 <- 0.6
glm_predict_4_0<- ifelse(glm_predict0 > threshold4, 1, 0)
glm_predict_5_0<- ifelse(glm_predict0 > threshold5, 1, 0)
glm_predict_6_0<- ifelse(glm_predict0 > threshold6, 1, 0)
create_confusion_matrix <- function(confusion_matrix) {
# Extract the confusion matrix table
cm_table <- as.data.frame(confusion_matrix$table)
#Extract F1 score
f1_score <- confusion_matrix$byClass["F1"]
# Plot the confusion matrix using ggplot2
ggplot(data = cm_table, aes(x = Reference, y = Prediction, fill = Freq)) +
geom_tile(color = "white") +
geom_text(aes(label = Freq), color = "black", size = 8) +
scale_fill_gradient(low = "white", high = "steelblue") +
labs(title = c("Confusion Matrix with F1-Score: ", f1_score), x = "Target", y = "Prediction") +
theme_minimal() +
theme(axis.text = element_text(size = 8),
plot.title = element_text(size = 8, face = "bold"))
}
# Confusion matrix with threshold = 0.4
table(rain_n_test0$RainTomorrow, glm_predict_4_0)
mean(glm_predict_4_0!=rain_n_test0$RainTomorrow)
cm4_0 <- confusionMatrix(data = factor(glm_predict_4_0), reference = factor(rain_n_test0$RainTomorrow), mode ='everything')
# Confusion matrix with threshold = 0.5
table(rain_n_test0$RainTomorrow, glm_predict_5_0)
mean(glm_predict_5_0!=rain_n_test0$RainTomorrow)
cm5_0 <- confusionMatrix(data = factor(glm_predict_5_0), reference = factor(rain_n_test0$RainTomorrow), mode ='everything')
# Confusion matrix with threshold = 0.6
table(rain_n_test0$RainTomorrow, glm_predict_6_0)
mean(glm_predict_6_0!=rain_n_test0$RainTomorrow)
cm6_0 <- confusionMatrix(data = factor(glm_predict_6_0), reference = factor(rain_n_test0$RainTomorrow), mode ='everything')
a0 <- create_confusion_matrix(cm4_0)
b0 <- create_confusion_matrix(cm5_0)
c0 <- create_confusion_matrix(cm6_0)
# Threshold of 0.05 is the best among thresholds in terms of accuracy, sensitivity, and specificity
cm_all0 = list(a0, b0, c0)
plot_width <- c(4, 4, 4)
grid.arrange(grobs = cm_all0, nrow = 3, width = plot_width)
#Test/Train Split
set.seed(123)
train0 <- sample(1:nrow(rain_n), nrow(rain_n) * 0.75)
# Calculate the test indices
test0 <- setdiff(1:nrow(rain_n), train0)
# Split the target variable into train and test sets
rain_n_train0 <- rain_n[train0,]
rain_n_test0 <- rain_n[test0 ,]
glm_model0 <- glm(data = rain_n_train0,
rain_n_train0$RainTomorrow ~ .,
family = binomial)
#R squared and Variance Inflation Factor (VIF)
#If the VIF value for a predictor variable is greater than 1, it indicates the presence of multicollinearity, suggesting that the predictor variable is highly correlated with other predictor variables in the model.
model_summary0 <- summary(glm_model0)
summary(glm_model0)
r2_0 <- 1 - (model_summary0$deviance/model_summary0$null.deviance) # 0.3698141
vif0 <- 1/(1-r2_0) # 1.586833
#Predict test with model
glm_predict0 <- predict(glm_model0, rain_n_test0, type = "response")
#Convert predictions into 0,1 based on different thresholds
threshold4 <- 0.4
threshold5 <- 0.5
threshold6 <- 0.6
glm_predict_4_0<- ifelse(glm_predict0 > threshold4, 1, 0)
glm_predict_5_0<- ifelse(glm_predict0 > threshold5, 1, 0)
glm_predict_6_0<- ifelse(glm_predict0 > threshold6, 1, 0)
create_confusion_matrix <- function(confusion_matrix) {
# Extract the confusion matrix table
cm_table <- as.data.frame(confusion_matrix$table)
#Extract F1 score
f1_score <- confusion_matrix$byClass["F1"]
# Plot the confusion matrix using ggplot2
ggplot(data = cm_table, aes(x = Reference, y = Prediction, fill = Freq)) +
geom_tile(color = "white") +
geom_text(aes(label = Freq), color = "black", size = 8) +
scale_fill_gradient(low = "white", high = "steelblue") +
labs(title = c("Confusion Matrix with F1-Score: ", {f1_score}), x = "Target", y = "Prediction") +
theme_minimal() +
theme(axis.text = element_text(size = 8),
plot.title = element_text(size = 8, face = "bold"))
}
# Confusion matrix with threshold = 0.4
table(rain_n_test0$RainTomorrow, glm_predict_4_0)
mean(glm_predict_4_0!=rain_n_test0$RainTomorrow)
cm4_0 <- confusionMatrix(data = factor(glm_predict_4_0), reference = factor(rain_n_test0$RainTomorrow), mode ='everything')
# Confusion matrix with threshold = 0.5
table(rain_n_test0$RainTomorrow, glm_predict_5_0)
mean(glm_predict_5_0!=rain_n_test0$RainTomorrow)
cm5_0 <- confusionMatrix(data = factor(glm_predict_5_0), reference = factor(rain_n_test0$RainTomorrow), mode ='everything')
# Confusion matrix with threshold = 0.6
table(rain_n_test0$RainTomorrow, glm_predict_6_0)
mean(glm_predict_6_0!=rain_n_test0$RainTomorrow)
cm6_0 <- confusionMatrix(data = factor(glm_predict_6_0), reference = factor(rain_n_test0$RainTomorrow), mode ='everything')
a0 <- create_confusion_matrix(cm4_0)
b0 <- create_confusion_matrix(cm5_0)
c0 <- create_confusion_matrix(cm6_0)
# Threshold of 0.05 is the best among thresholds in terms of accuracy, sensitivity, and specificity
cm_all0 = list(a0, b0, c0)
plot_width <- c(4, 4, 4)
grid.arrange(grobs = cm_all0, nrow = 3, width = plot_width)
#Test/Train Split
set.seed(123)
train0 <- sample(1:nrow(rain_n), nrow(rain_n) * 0.75)
# Calculate the test indices
test0 <- setdiff(1:nrow(rain_n), train0)
# Split the target variable into train and test sets
rain_n_train0 <- rain_n[train0,]
rain_n_test0 <- rain_n[test0 ,]
glm_model0 <- glm(data = rain_n_train0,
rain_n_train0$RainTomorrow ~ .,
family = binomial)
#R squared and Variance Inflation Factor (VIF)
#If the VIF value for a predictor variable is greater than 1, it indicates the presence of multicollinearity, suggesting that the predictor variable is highly correlated with other predictor variables in the model.
model_summary0 <- summary(glm_model0)
summary(glm_model0)
r2_0 <- 1 - (model_summary0$deviance/model_summary0$null.deviance) # 0.3698141
vif0 <- 1/(1-r2_0) # 1.586833
#Predict test with model
glm_predict0 <- predict(glm_model0, rain_n_test0, type = "response")
#Convert predictions into 0,1 based on different thresholds
threshold4 <- 0.4
threshold5 <- 0.5
threshold6 <- 0.6
glm_predict_4_0<- ifelse(glm_predict0 > threshold4, 1, 0)
glm_predict_5_0<- ifelse(glm_predict0 > threshold5, 1, 0)
glm_predict_6_0<- ifelse(glm_predict0 > threshold6, 1, 0)
create_confusion_matrix <- function(confusion_matrix) {
# Extract the confusion matrix table
cm_table <- as.data.frame(confusion_matrix$table)
#Extract F1 score
f1_score <- confusion_matrix$byClass["F1"]
# Plot the confusion matrix using ggplot2
ggplot(data = cm_table, aes(x = Reference, y = Prediction, fill = Freq)) +
geom_tile(color = "white") +
geom_text(aes(label = Freq), color = "black", size = 8) +
scale_fill_gradient(low = "white", high = "steelblue") +
labs(title = paste("Confusion Matrix with F1-Score:", f1_score), x = "Target", y = "Prediction") +
theme_minimal() +
theme(axis.text = element_text(size = 8),
plot.title = element_text(size = 8, face = "bold"))
}
# Confusion matrix with threshold = 0.4
table(rain_n_test0$RainTomorrow, glm_predict_4_0)
mean(glm_predict_4_0!=rain_n_test0$RainTomorrow)
cm4_0 <- confusionMatrix(data = factor(glm_predict_4_0), reference = factor(rain_n_test0$RainTomorrow), mode ='everything')
# Confusion matrix with threshold = 0.5
table(rain_n_test0$RainTomorrow, glm_predict_5_0)
mean(glm_predict_5_0!=rain_n_test0$RainTomorrow)
cm5_0 <- confusionMatrix(data = factor(glm_predict_5_0), reference = factor(rain_n_test0$RainTomorrow), mode ='everything')
# Confusion matrix with threshold = 0.6
table(rain_n_test0$RainTomorrow, glm_predict_6_0)
mean(glm_predict_6_0!=rain_n_test0$RainTomorrow)
cm6_0 <- confusionMatrix(data = factor(glm_predict_6_0), reference = factor(rain_n_test0$RainTomorrow), mode ='everything')
a0 <- create_confusion_matrix(cm4_0)
b0 <- create_confusion_matrix(cm5_0)
c0 <- create_confusion_matrix(cm6_0)
# Threshold of 0.05 is the best among thresholds in terms of accuracy, sensitivity, and specificity
cm_all0 = list(a0, b0, c0)
plot_width <- c(4, 4, 4)
grid.arrange(grobs = cm_all0, nrow = 3, width = plot_width)
#Test/Train Split
set.seed(123)
train0 <- sample(1:nrow(rain_n), nrow(rain_n) * 0.75)
# Calculate the test indices
test0 <- setdiff(1:nrow(rain_n), train0)
# Split the target variable into train and test sets
rain_n_train0 <- rain_n[train0,]
rain_n_test0 <- rain_n[test0 ,]
glm_model0 <- glm(data = rain_n_train0,
rain_n_train0$RainTomorrow ~ .,
family = binomial)
#R squared and Variance Inflation Factor (VIF)
#If the VIF value for a predictor variable is greater than 1, it indicates the presence of multicollinearity, suggesting that the predictor variable is highly correlated with other predictor variables in the model.
model_summary0 <- summary(glm_model0)
summary(glm_model0)
r2_0 <- 1 - (model_summary0$deviance/model_summary0$null.deviance) # 0.3698141
vif0 <- 1/(1-r2_0) # 1.586833
#Predict test with model
glm_predict0 <- predict(glm_model0, rain_n_test0, type = "response")
#Convert predictions into 0,1 based on different thresholds
threshold4 <- 0.4
threshold5 <- 0.5
threshold6 <- 0.6
glm_predict_4_0<- ifelse(glm_predict0 > threshold4, 1, 0)
glm_predict_5_0<- ifelse(glm_predict0 > threshold5, 1, 0)
glm_predict_6_0<- ifelse(glm_predict0 > threshold6, 1, 0)
create_confusion_matrix <- function(confusion_matrix) {
# Extract the confusion matrix table
cm_table <- as.data.frame(confusion_matrix$table)
#Extract F1 score
f1_score <- confusion_matrix$byClass["F1"]
# Plot the confusion matrix using ggplot2
ggplot(data = cm_table, aes(x = Reference, y = Prediction, fill = Freq)) +
geom_tile(color = "white") +
geom_text(aes(label = Freq), color = "black", size = 8) +
scale_fill_gradient(low = "white", high = "steelblue") +
labs(title = paste("Confusion Matrix with F1-Score:", round(f1_score, 3)), x = "Target", y = "Prediction") +
theme_minimal() +
theme(axis.text = element_text(size = 8),
plot.title = element_text(size = 8, face = "bold"))
}
# Confusion matrix with threshold = 0.4
table(rain_n_test0$RainTomorrow, glm_predict_4_0)
mean(glm_predict_4_0!=rain_n_test0$RainTomorrow)
cm4_0 <- confusionMatrix(data = factor(glm_predict_4_0), reference = factor(rain_n_test0$RainTomorrow), mode ='everything')
# Confusion matrix with threshold = 0.5
table(rain_n_test0$RainTomorrow, glm_predict_5_0)
mean(glm_predict_5_0!=rain_n_test0$RainTomorrow)
cm5_0 <- confusionMatrix(data = factor(glm_predict_5_0), reference = factor(rain_n_test0$RainTomorrow), mode ='everything')
# Confusion matrix with threshold = 0.6
table(rain_n_test0$RainTomorrow, glm_predict_6_0)
mean(glm_predict_6_0!=rain_n_test0$RainTomorrow)
cm6_0 <- confusionMatrix(data = factor(glm_predict_6_0), reference = factor(rain_n_test0$RainTomorrow), mode ='everything')
a0 <- create_confusion_matrix(cm4_0)
b0 <- create_confusion_matrix(cm5_0)
c0 <- create_confusion_matrix(cm6_0)
# Threshold of 0.05 is the best among thresholds in terms of accuracy, sensitivity, and specificity
cm_all0 = list(a0, b0, c0)
plot_width <- c(4, 4, 4)
grid.arrange(grobs = cm_all0, nrow = 3, width = plot_width)
#Test/Train Split
set.seed(123)
train_balanced <- sample(1:nrow(rain_balanced), nrow(rain_balanced) * 0.75)
# Calculate the test indices
test_balanced <- setdiff(1:nrow(rain_balanced), train_balanced)
# Split the target variable into train and test sets
rain_balanced_train <- rain_balanced[train_balanced,]
rain_balanced_test <- rain_balanced[test_balanced ,]
glm_model_balanced <- glm(data = rain_balanced_train,
rain_balanced_train$RainTomorrow ~ .,
family = binomial)
#R squared and Variance Inflation Factor (VIF)
#If the VIF value for a predictor variable is greater than 1, it indicates the presence of multicollinearity, suggesting that the predictor variable is highly correlated with other predictor variables in the model.
model_summary_balanced <- summary(glm_model_balanced)
summary(glm_model_balanced)
r2_balanced <- 1 - (model_summary_balanced$deviance/model_summary_balanced$null.deviance) # 0.3849359
vif_balanced <- 1/(1-r2_balanced) # 1.625847
#Predict test with model
glm_predict_balanced <- predict(glm_model_balanced, rain_balanced_test, type = "response")
#Convert predictions into 0,1 based on different thresholds
glm_predict_4_balanced<- ifelse(glm_predict_balanced > threshold4, 1, 0)
glm_predict_5_balanced<- ifelse(glm_predict_balanced > threshold5, 1, 0)
glm_predict_6_balanced<- ifelse(glm_predict_balanced > threshold6, 1, 0)
# Confusion matrix with threshold = 0.4
table(rain_balanced_test$RainTomorrow, glm_predict_4_balanced)
mean(glm_predict_4_balanced!=rain_balanced_test$RainTomorrow)
cm4_balanced <- confusionMatrix(data = factor(glm_predict_4_balanced), reference = factor(rain_balanced_test$RainTomorrow), mode ='everything')
# Confusion matrix with threshold = 0.5
table(rain_balanced_test$RainTomorrow, glm_predict_5_balanced)
mean(glm_predict_5_balanced!=rain_balanced_test$RainTomorrow)
cm5_balanced <- confusionMatrix(data = factor(glm_predict_5_balanced), reference = factor(rain_balanced_test$RainTomorrow), mode ='everything')
# Confusion matrix with threshold = 0.6
table(rain_balanced_test$RainTomorrow, glm_predict_6_balanced)
mean(glm_predict_6_balanced!=rain_balanced_test$RainTomorrow)
cm6_balanced <- confusionMatrix(data = factor(glm_predict_6_balanced), reference = factor(rain_balanced_test$RainTomorrow), mode ='everything')
a_balanced <- create_confusion_matrix(cm4_balanced)
b_balanced <- create_confusion_matrix(cm5_balanced)
c_balanced <- create_confusion_matrix(cm6_balanced)
# Threshold of 0.05 is the best among thresholds in terms of accuracy, sensitivity, and specificity
cm_all_balanced = list(a_balanced, b_balanced, c_balanced)
plot_width <- c(4, 4, 4)
grid.arrange(grobs = cm_all_balanced, nrow = 3, width = plot_width)
# Model Definition
glm_model <- glm(data = rain_subset_train,
rain_subset_train$RainTomorrow ~ .,
family = binomial)
#R squared and Variance Inflation Factor (VIF)
#If the VIF value for a predictor variable is greater than 1, it indicates the presence of multicollinearity, suggesting that the predictor variable is highly correlated with other predictor variables in the model.
model_summary <- summary(glm_model)
summary(glm_model)
r2 <- 1 - (model_summary$deviance/model_summary$null.deviance) # 0.3845522
vif <- 1/(1-r2) # 1.624833
#Predict test with model
glm_predict <- predict(glm_model, rain_subset_test, type = "response")
#Convert predictions into 0,1 based on different thresholds
glm_predict_4<- ifelse(glm_predict > threshold4, 1, 0)
glm_predict_5<- ifelse(glm_predict > threshold5, 1, 0)
glm_predict_6<- ifelse(glm_predict > threshold6, 1, 0)
# Confusion matrix with threshold = 0.4
table(rain_subset_test$RainTomorrow, glm_predict_4)
mean(glm_predict_4!=rain_subset_test$RainTomorrow)
cm4 <- confusionMatrix(data = factor(glm_predict_4), reference = factor(rain_subset_test$RainTomorrow), mode ='everything')
# Confusion matrix with threshold = 0.5
table(rain_subset_test$RainTomorrow, glm_predict_5)
mean(glm_predict_5!=rain_subset_test$RainTomorrow)
cm5 <- confusionMatrix(data = factor(glm_predict_5), reference = factor(rain_subset_test$RainTomorrow), mode ='everything')
# Confusion matrix with threshold = 0.6
table(rain_subset_test$RainTomorrow, glm_predict_6)
mean(glm_predict_6!=rain_subset_test$RainTomorrow)
cm6 <- confusionMatrix(data = factor(glm_predict_6), reference = factor(rain_subset_test$RainTomorrow), mode ='everything')
a <- create_confusion_matrix(cm4)
b <- create_confusion_matrix(cm5)
c <- create_confusion_matrix(cm6)
# Threshold of 0.05 is the best among thresholds in terms of accuracy, sensitivity, and specificity
cm_all = list(a, b, c)
plot_width <- c(4, 4, 4)
grid.arrange(grobs = cm_all, nrow = 3, width = plot_width)
print(cm4_0)
mean(glm_predict_4_0!=rain_n_test0$RainTomorrow)
mean(glm_predict_5_0!=rain_n_test0$RainTomorrow)
mean(glm_predict_6_0!=rain_n_test0$RainTomorrow)
mean(glm_predict_4_balanced!=rain_balanced_test$RainTomorrow)
mean(glm_predict_5_balanced!=rain_balanced_test$RainTomorrow)
mean(glm_predict_6_balanced!=rain_balanced_test$RainTomorrow)
mean(glm_predict_4!=rain_subset_test$RainTomorrow)
mean(glm_predict_5!=rain_subset_test$RainTomorrow)
mean(glm_predict_6!=rain_subset_test$RainTomorrow)
mean(glm_predict_4!=rain_subset_test$RainTomorrow)
mean(glm_predict_5!=rain_subset_test$RainTomorrow)
print(cm4)
print(cm5)
print(cm6)
models = c("Simple GLM", "GLM with Balancing", "GLM with Balancing and Feature Selection")
model_suffix = c("_balanced", "_0", "")
thresholds <- c(4, 5, 6)
for (model in model_suffix) {
for (threshold in thresholds) {
# Calculate the F1 score for each combination of model and threshold
print(cm{threshold}{model_suffix}$byClass["F1"])
for (model in model_suffix) {
for (threshold in thresholds) {
# Calculate the F1 score for each combination of model and threshold
print(paste("cm",threshold,model_suffix))
}
}
for (model in model_suffix) {
for (threshold in thresholds) {
# Calculate the F1 score for each combination of model and threshold
print(paste("cm",thresholds[threshold],model_suffix[model]))
}
}
for (model in model_suffix) {
for (threshold in thresholds) {
# Calculate the F1 score for each combination of model and threshold
print(paste("cm",threshold,model))
}
}
for (model in model_suffix) {
for (threshold in thresholds) {
# Calculate the F1 score for each combination of model and threshold
paste("cm",threshold,model)
}
}
for (model in model_suffix) {
for (threshold in thresholds) {
# Calculate the F1 score for each combination of model and threshold
print(paste("cm",threshold,model, sep=''))
}
}
for (model in model_suffix) {
for (threshold in thresholds) {
# Calculate the F1 score for each combination of model and threshold
print(paste0("cm",threshold,model))
}
}
f1_scores <- data.frame(Model = character(), Threshold = numeric(), F1_Score = numeric(), stringsAsFactors = FALSE)
for (model in model_suffix) {
for (threshold in thresholds) {
# Calculate the F1 score for each combination of model and threshold
f1_score <- paste0("cm",threshold,model)$byClass["F1"]
f1_scores <- rbind(f1_scores, data.frame(Model = model, Threshold = threshold, F1_Score = f1_score, stringsAsFactors = FALSE))
}
}
for (model in model_suffix) {
for (threshold in thresholds) {
# Calculate the F1 score for each combination of model and threshold
#f1_score <-
print(paste0("cm",threshold,model)$byClass["F1"])
#f1_scores <- rbind(f1_scores, data.frame(Model = model, Threshold = threshold, F1_Score = f1_score, stringsAsFactors = FALSE))
}
}
for (model in model_suffix) {
for (threshold in thresholds) {
# Calculate the F1 score for each combination of model and threshold
#f1_score <-
print(paste0("cm",threshold,model))
#$byClass["F1"])
#f1_scores <- rbind(f1_scores, data.frame(Model = model, Threshold = threshold, F1_Score = f1_score, stringsAsFactors = FALSE))
}
}
for (model in model_suffix) {
for (threshold in thresholds) {
# Calculate the F1 score for each combination of model and threshold
f1_score <- paste0("cm",threshold,model, quote = FALSE)$byClass["F1"]
f1_scores <- rbind(f1_scores, data.frame(Model = model, Threshold = threshold, F1_Score = f1_score, stringsAsFactors = FALSE))
}
}
f1_scores <- data.frame(Model = character(), Threshold = numeric(), F1_Score = numeric(), stringsAsFactors = FALSE)
for (model in model_suffix) {
for (threshold in thresholds) {
# Calculate the F1 score for each combination of model and threshold
#f1_score <- paste0("cm",threshold,model, quote = FALSE)$byClass["F1"]
f1_score <- cm5$byClass["F1"]
f1_scores <- rbind(f1_scores, data.frame(Model = model, Threshold = threshold, F1_Score = f1_score, stringsAsFactors = FALSE))
}
}
f1_scores
f1_scores <- data.frame(Model = character(), Threshold = numeric(), F1_Score = numeric(), stringsAsFactors = FALSE)
for (model in model_suffix) {
for (threshold in thresholds) {
# Calculate the F1 score for each combination of model and threshold
cm <- paste0("cm",threshold,model, quote = FALSE)
f1_score <- cm$byClass["F1"]
f1_scores <- rbind(f1_scores, data.frame(Model = model, Threshold = threshold, F1_Score = f1_score, stringsAsFactors = FALSE))
}
}
f1_scores <- data.frame(Model = character(), Threshold = numeric(), F1_Score = numeric(), stringsAsFactors = FALSE)
for (model in model_suffix) {
for (threshold in thresholds) {
# Calculate the F1 score for each combination of model and threshold
cm_name <- paste0("cm",threshold,model, quote = FALSE)
cm <- get(cm_name)
f1_score <- cm$byClass["F1"]
f1_scores <- rbind(f1_scores, data.frame(Model = model, Threshold = threshold, F1_Score = f1_score, stringsAsFactors = FALSE))
}
}
f1_scores <- data.frame(Model = character(), Threshold = numeric(), F1_Score = numeric(), stringsAsFactors = FALSE)
for (model in model_suffix) {
for (threshold in thresholds) {
# Calculate the F1 score for each combination of model and threshold
cm_name <- paste0("cm",threshold,model)
cm <- get(cm_name)
f1_score <- cm$byClass["F1"]
f1_scores <- rbind(f1_scores, data.frame(Model = model, Threshold = threshold, F1_Score = f1_score, stringsAsFactors = FALSE))
}
}
f1_scores
models <- c("Simple GLM", "GLM with Balancing", "GLM with Balancing and Feature Selection")
model_suffix <- c("_balanced", "_0", "")
thresholds <- c(4, 5, 6)
threshold_values <- c(0.4, 0.5, 0.6)
f1_scores <- data.frame(Model = character(), Threshold = numeric(), F1_Score = numeric(), stringsAsFactors = FALSE)
for (i in 1:length(models)) {
model <- models[i]
threshold <- thresholds[i]
threshold_value <- threshold_values[i]
# Calculate the F1 score for each combination of model and threshold
cm_name <- paste0("cm", threshold, model_suffix[i])
cm <- get(cm_name)
f1_score <- cm$byClass["F1"]
# Add the F1 score to the data frame
f1_scores <- rbind(f1_scores, data.frame(Model = model, Threshold = threshold_value, F1_Score = f1_score, stringsAsFactors = FALSE))
}
f1_scores
models <- c("Simple GLM", "GLM with Balancing", "GLM with Balancing and Feature Selection")
model_suffix <- c("_balanced", "_0", "")
thresholds <- c(4, 5, 6)
f1_scores <- data.frame(Model = character(), Threshold = numeric(), F1_Score = numeric(), stringsAsFactors = FALSE)
for (model in model_suffix) {
for (threshold in thresholds) {
# Calculate the F1 score for each combination of model and threshold
cm_name <- paste0("cm",threshold,model)
cm <- get(cm_name)
f1_score <- cm$byClass["F1"]
f1_scores <- rbind(f1_scores, data.frame(Model = model, Threshold = threshold, F1_Score = f1_score, stringsAsFactors = FALSE))
}
}
f1_scores
kable(f1_scores, format = "markdown")
install.packages("knitr")
kable(f1_scores, format = "markdown")
models <- c("Simple GLM", "GLM with Balancing", "GLM with Balancing and Feature Selection")
model_suffix <- c("_balanced", "_0", "")
thresholds <- c(4, 5, 6)
threshold_values <- c(0.4, 0.5, 0.6)
f1_scores <- data.frame(Model = character(), Threshold = numeric(), F1_Score = numeric(), stringsAsFactors = FALSE)
for (model in models) {
for (i in 1:length(thresholds)) {
threshold <- thresholds[i]
threshold_value <- threshold_values[i]
# Calculate the F1 score for each combination of model and threshold
cm_name <- paste0("cm", threshold, model_suffix[i])
cm <- get(cm_name)
f1_score <- cm$byClass["F1"]
# Add the F1 score to the data frame
f1_scores <- rbind(f1_scores, data.frame(Model = model, Threshold = threshold_value, F1_Score = f1_score, stringsAsFactors = FALSE))
}
}
f1_scores
kable(f1_scores, format = "markdown")
f1_scores
## Summary Statistics: F1-Score
models <- c("Simple GLM", "GLM with Balancing", "GLM with Balancing and Feature Selection")
model_suffix <- c("_balanced", "_0", "")
thresholds <- c(4, 5, 6)
threshold_values <- c(0.4, 0.5, 0.6)
f1_scores <- data.frame(Model = character(), Threshold = numeric(), F1_Score = numeric(), stringsAsFactors = FALSE)
for (model in models) {
for (i in 1:length(thresholds)) {
threshold <- thresholds[i]
threshold_value <- threshold_values[i]
# Calculate the F1 score for each combination of model and threshold
cm_name <- paste0("cm", thresholds[i], model_suffix[i])
cm <- get(cm_name)
f1_score <- cm$byClass["F1"]
# Add the F1 score to the data frame
f1_scores <- rbind(f1_scores, data.frame(Model = model, Threshold = threshold_value, F1_Score = f1_score, stringsAsFactors = FALSE))
}
}
f1_scores
